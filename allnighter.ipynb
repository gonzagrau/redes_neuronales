{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84511,"databundleVersionId":9468663,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T20:12:31.158382Z","iopub.execute_input":"2024-10-29T20:12:31.159167Z","iopub.status.idle":"2024-10-29T20:12:31.167451Z","shell.execute_reply.started":"2024-10-29T20:12:31.159128Z","shell.execute_reply":"2024-10-29T20:12:31.166430Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"/kaggle/input/bajlecgrausayegh/keras/default/1/config.json\n/kaggle/input/bajlecgrausayegh/keras/default/1/metadata.json\n/kaggle/input/bajlecgrausayegh/keras/default/1/model.weights.h5\n/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_fine.npy\n/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_coarse.npy\n/kaggle/input/dl-itba-cifar-100-2024-q-1/fine_label_names.pck\n/kaggle/input/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck\n/kaggle/input/dl-itba-cifar-100-2024-q-1/x_test.npy\n/kaggle/input/dl-itba-cifar-100-2024-q-1/x_train.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.169313Z","iopub.execute_input":"2024-10-29T20:12:31.170203Z","iopub.status.idle":"2024-10-29T20:12:31.177092Z","shell.execute_reply.started":"2024-10-29T20:12:31.170167Z","shell.execute_reply":"2024-10-29T20:12:31.176180Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten, ReLU, PReLU, Activation\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop\nfrom tensorflow.keras.regularizers import l1, l2\nfrom tensorflow.keras.constraints import MaxNorm\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers, models, regularizers, constraints","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:41:18.700597Z","iopub.execute_input":"2024-10-29T20:41:18.700984Z","iopub.status.idle":"2024-10-29T20:41:18.707524Z","shell.execute_reply.started":"2024-10-29T20:41:18.700947Z","shell.execute_reply":"2024-10-29T20:41:18.706508Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"x_train = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/x_train.npy\")\nx_test = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/x_test.npy\")\ny_train_coarse = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_coarse.npy\")\ny_train_fine = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_fine.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.191891Z","iopub.execute_input":"2024-10-29T20:12:31.192295Z","iopub.status.idle":"2024-10-29T20:12:31.270549Z","shell.execute_reply.started":"2024-10-29T20:12:31.192248Z","shell.execute_reply":"2024-10-29T20:12:31.269720Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.271748Z","iopub.execute_input":"2024-10-29T20:12:31.272080Z","iopub.status.idle":"2024-10-29T20:12:31.276496Z","shell.execute_reply.started":"2024-10-29T20:12:31.272045Z","shell.execute_reply":"2024-10-29T20:12:31.275541Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/fine_label_names.pck\", \"rb\") as f:\n    labels_fine = pickle.load(f)\nwith open(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck\", \"rb\") as f:\n    labels_coarse = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.278688Z","iopub.execute_input":"2024-10-29T20:12:31.279021Z","iopub.status.idle":"2024-10-29T20:12:31.288699Z","shell.execute_reply.started":"2024-10-29T20:12:31.278988Z","shell.execute_reply":"2024-10-29T20:12:31.287778Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"y_train_fine.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.290022Z","iopub.execute_input":"2024-10-29T20:12:31.290336Z","iopub.status.idle":"2024-10-29T20:12:31.298401Z","shell.execute_reply.started":"2024-10-29T20:12:31.290303Z","shell.execute_reply":"2024-10-29T20:12:31.297592Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"(50000,)"},"metadata":{}}]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.299516Z","iopub.execute_input":"2024-10-29T20:12:31.299844Z","iopub.status.idle":"2024-10-29T20:12:31.308005Z","shell.execute_reply.started":"2024-10-29T20:12:31.299811Z","shell.execute_reply":"2024-10-29T20:12:31.307124Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"(50000, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"x_train,x_val, y_train, y_val = train_test_split(x_train, y_train_fine, test_size=0.1, stratify=y_train_fine)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.309132Z","iopub.execute_input":"2024-10-29T20:12:31.309994Z","iopub.status.idle":"2024-10-29T20:12:31.388896Z","shell.execute_reply.started":"2024-10-29T20:12:31.309950Z","shell.execute_reply":"2024-10-29T20:12:31.388083Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"y_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.390185Z","iopub.execute_input":"2024-10-29T20:12:31.390579Z","iopub.status.idle":"2024-10-29T20:12:31.397208Z","shell.execute_reply.started":"2024-10-29T20:12:31.390535Z","shell.execute_reply":"2024-10-29T20:12:31.396316Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"(5000,)"},"metadata":{}}]},{"cell_type":"code","source":"x_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.398496Z","iopub.execute_input":"2024-10-29T20:12:31.398842Z","iopub.status.idle":"2024-10-29T20:12:31.408111Z","shell.execute_reply.started":"2024-10-29T20:12:31.398799Z","shell.execute_reply":"2024-10-29T20:12:31.407263Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"(5000, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"x_train_horizontal_flip= x_train[:,:,::-1,:]\nx_train_vertical_flip = x_train[:,::-1,:,:]\nx_train_vh_flip =x_train[:, ::-1, ::-1, :]\n\nx_train_dup = np.concatenate([x_train,x_train_horizontal_flip,x_train_vertical_flip,x_train_vh_flip],axis=0)\nx_train_dup = np.concatenate([x_train,x_train_horizontal_flip],axis=0)\ny_train_dup = np.concatenate([y_train, y_train,y_train, y_train], axis=0)\ny_train_dup = np.concatenate([y_train, y_train], axis=0)\n\nx_train_bis = x_train_dup.copy()\nx_train_bis_bis = x_train_dup.copy()\n\n#desplazamientos right and left \nx_train_bis[:,:,1:,:] =x_train_dup[:,:,:-1,:]\nx_train_bis_bis[:,:,:-1,:] =x_train_dup[:,:,1:,:]\n\nx_train_dup = np.concatenate([x_train_dup, x_train_bis, x_train_bis_bis],axis=0)\ny_train_dup = np.concatenate([y_train_dup, y_train_dup, y_train_dup], axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:31.411978Z","iopub.execute_input":"2024-10-29T20:12:31.412868Z","iopub.status.idle":"2024-10-29T20:12:34.070278Z","shell.execute_reply.started":"2024-10-29T20:12:31.412825Z","shell.execute_reply":"2024-10-29T20:12:34.069430Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"print(f'Original dataset size: {len(x_train)}')\nprint(f'Augmented dataset size: {len(x_train_dup)}')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:34.071405Z","iopub.execute_input":"2024-10-29T20:12:34.071716Z","iopub.status.idle":"2024-10-29T20:12:34.076477Z","shell.execute_reply.started":"2024-10-29T20:12:34.071682Z","shell.execute_reply":"2024-10-29T20:12:34.075629Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"Original dataset size: 45000\nAugmented dataset size: 270000\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train_dup.shape, y_train_dup.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:12:34.077943Z","iopub.execute_input":"2024-10-29T20:12:34.078298Z","iopub.status.idle":"2024-10-29T20:12:34.090442Z","shell.execute_reply.started":"2024-10-29T20:12:34.078254Z","shell.execute_reply":"2024-10-29T20:12:34.089572Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"((270000, 32, 32, 3), (270000,))"},"metadata":{}}]},{"cell_type":"code","source":"from datetime import datetime\nimport keras","metadata":{"execution":{"iopub.status.busy":"2024-10-29T20:22:11.150380Z","iopub.execute_input":"2024-10-29T20:22:11.151008Z","iopub.status.idle":"2024-10-29T20:22:11.155524Z","shell.execute_reply.started":"2024-10-29T20:22:11.150960Z","shell.execute_reply":"2024-10-29T20:22:11.154427Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"def create_model(input_shape=(32, 32, 3),l2_lambda=0.001):\n    # Input layer for images\n    inputs = layers.Input(shape=input_shape)\n    \n    # Flattening layer\n    x = layers.Flatten()(inputs)\n    \n    # Normalization layer\n    x = layers.Lambda(lambda x: x/np.float16(255.0))(x)\n    \n    # Dense layers with L2 regularization, dropout, and batch normalization\n    n = 10\n    for i in range(6):\n        x = Dense(2**n)(x)#,\n                  #kernel_regularizer=regularizers.L2(l2_lambda))(x)\n        x = BatchNormalization()(x)\n        x = ReLU()(x)\n        x = Dropout(0.3)(x)\n    \n    # Output layer with softmax for 100 classes\n    fine_output = layers.Dense(100, activation='softmax', name='fine_output')(x)   \n  \n    # Create model\n    model = models.Model(inputs=inputs, outputs=[fine_output], name=f\"mlp_allnighter\")\n    \n    return model\n\nprint(f\"Success at {datetime.now().time()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:07:42.966618Z","iopub.execute_input":"2024-10-29T21:07:42.967027Z","iopub.status.idle":"2024-10-29T21:07:42.975524Z","shell.execute_reply.started":"2024-10-29T21:07:42.966990Z","shell.execute_reply":"2024-10-29T21:07:42.974579Z"},"trusted":true},"execution_count":188,"outputs":[{"name":"stdout","text":"Success at 21:07:42.971523\n","output_type":"stream"}]},{"cell_type":"code","source":"model = create_model()\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss={'fine_output': 'sparse_categorical_crossentropy'},\n    metrics={'fine_output': 'accuracy' }\n             )\n\n# Early stopping callback\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True,verbose= 1)\ntb = TensorBoard(log_dir=\"logs\")\n\n# Display the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:07:45.771766Z","iopub.execute_input":"2024-10-29T21:07:45.772883Z","iopub.status.idle":"2024-10-29T21:07:45.937678Z","shell.execute_reply.started":"2024-10-29T21:07:45.772838Z","shell.execute_reply":"2024-10-29T21:07:45.936833Z"},"trusted":true},"execution_count":189,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"mlp_allnighter\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_allnighter\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_32 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_32 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lambda_32 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_115 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m3,146,752\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_115         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_92 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_116 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_116         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_93 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_117 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_117         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_94 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_118 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_118         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_95 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_119 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_119         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_96 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_120 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_120         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_97 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m102,500\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lambda_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,146,752</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_115         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_116         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_117         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_118         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_119         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_120         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ re_lu_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,500</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,521,828\u001b[0m (32.51 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,521,828</span> (32.51 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,509,540\u001b[0m (32.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,509,540</span> (32.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m12,288\u001b[0m (48.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> (48.00 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Fit the model\nhistory = model.fit(x=x_train_dup,   \n                    y={'fine_output': y_train_dup},\n                    validation_data=(x_val, {'fine_output': y_val}),\n                    epochs=50,                        \n                    batch_size=512,  # approximately 1000 batches per epoch                    \n                    callbacks=[tb, early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:07:48.639572Z","iopub.execute_input":"2024-10-29T21:07:48.639956Z","iopub.status.idle":"2024-10-29T21:11:49.131712Z","shell.execute_reply.started":"2024-10-29T21:07:48.639908Z","shell.execute_reply":"2024-10-29T21:11:49.130859Z"},"trusted":true},"execution_count":190,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0392 - loss: 4.6158","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730236094.255805      96 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_5', 504 bytes spill stores, 544 bytes spill loads\nptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 24ms/step - accuracy: 0.0393 - loss: 4.6152 - val_accuracy: 0.1350 - val_loss: 3.7386\nEpoch 2/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1177 - loss: 3.7780 - val_accuracy: 0.1746 - val_loss: 3.4879\nEpoch 3/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1606 - loss: 3.5158 - val_accuracy: 0.2016 - val_loss: 3.3396\nEpoch 4/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1899 - loss: 3.3412 - val_accuracy: 0.2052 - val_loss: 3.3194\nEpoch 5/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2140 - loss: 3.2118 - val_accuracy: 0.2296 - val_loss: 3.1916\nEpoch 6/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2337 - loss: 3.1019 - val_accuracy: 0.2436 - val_loss: 3.1101\nEpoch 7/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2523 - loss: 3.0045 - val_accuracy: 0.2506 - val_loss: 3.0531\nEpoch 8/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2672 - loss: 2.9227 - val_accuracy: 0.2522 - val_loss: 3.0601\nEpoch 9/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2804 - loss: 2.8502 - val_accuracy: 0.2544 - val_loss: 3.0200\nEpoch 10/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2957 - loss: 2.7760 - val_accuracy: 0.2706 - val_loss: 2.9915\nEpoch 11/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3083 - loss: 2.7150 - val_accuracy: 0.2642 - val_loss: 3.0237\nEpoch 12/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3207 - loss: 2.6533 - val_accuracy: 0.2758 - val_loss: 2.9485\nEpoch 13/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3322 - loss: 2.5902 - val_accuracy: 0.2704 - val_loss: 2.9847\nEpoch 14/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3410 - loss: 2.5481 - val_accuracy: 0.2874 - val_loss: 2.9453\nEpoch 15/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3509 - loss: 2.4989 - val_accuracy: 0.3010 - val_loss: 2.8554\nEpoch 16/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3600 - loss: 2.4521 - val_accuracy: 0.3044 - val_loss: 2.8342\nEpoch 17/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3704 - loss: 2.4042 - val_accuracy: 0.2960 - val_loss: 2.8796\nEpoch 18/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3797 - loss: 2.3538 - val_accuracy: 0.3058 - val_loss: 2.8169\nEpoch 19/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3860 - loss: 2.3193 - val_accuracy: 0.3132 - val_loss: 2.7858\nEpoch 20/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3948 - loss: 2.2815 - val_accuracy: 0.2956 - val_loss: 2.9182\nEpoch 21/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4020 - loss: 2.2451 - val_accuracy: 0.3086 - val_loss: 2.8162\nEpoch 22/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4112 - loss: 2.2030 - val_accuracy: 0.3188 - val_loss: 2.7867\nEpoch 23/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4214 - loss: 2.1570 - val_accuracy: 0.3104 - val_loss: 2.8659\nEpoch 24/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4239 - loss: 2.1318 - val_accuracy: 0.3128 - val_loss: 2.8523\nEpoch 25/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4323 - loss: 2.0958 - val_accuracy: 0.3178 - val_loss: 2.8195\nEpoch 26/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4441 - loss: 2.0538 - val_accuracy: 0.3124 - val_loss: 2.8727\nEpoch 27/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4474 - loss: 2.0214 - val_accuracy: 0.3212 - val_loss: 2.8099\nEpoch 28/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4535 - loss: 1.9994 - val_accuracy: 0.3190 - val_loss: 2.8930\nEpoch 29/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4639 - loss: 1.9604 - val_accuracy: 0.3298 - val_loss: 2.7954\nEpoch 30/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4706 - loss: 1.9315 - val_accuracy: 0.3262 - val_loss: 2.8311\nEpoch 31/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4763 - loss: 1.8942 - val_accuracy: 0.3184 - val_loss: 2.8937\nEpoch 32/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4820 - loss: 1.8720 - val_accuracy: 0.3348 - val_loss: 2.8207\nEpoch 33/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4906 - loss: 1.8373 - val_accuracy: 0.3278 - val_loss: 2.8736\nEpoch 34/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4959 - loss: 1.8121 - val_accuracy: 0.3336 - val_loss: 2.8565\nEpoch 35/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5015 - loss: 1.7829 - val_accuracy: 0.3454 - val_loss: 2.7993\nEpoch 36/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5072 - loss: 1.7600 - val_accuracy: 0.3350 - val_loss: 2.8636\nEpoch 37/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5152 - loss: 1.7307 - val_accuracy: 0.3412 - val_loss: 2.8436\nEpoch 38/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5206 - loss: 1.7049 - val_accuracy: 0.3224 - val_loss: 3.0173\nEpoch 39/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5252 - loss: 1.6787 - val_accuracy: 0.3434 - val_loss: 2.8744\nEpoch 40/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5329 - loss: 1.6501 - val_accuracy: 0.3362 - val_loss: 2.9466\nEpoch 41/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5363 - loss: 1.6306 - val_accuracy: 0.3358 - val_loss: 2.9263\nEpoch 42/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5442 - loss: 1.6036 - val_accuracy: 0.3484 - val_loss: 2.9171\nEpoch 43/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5494 - loss: 1.5773 - val_accuracy: 0.3508 - val_loss: 2.8677\nEpoch 44/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5561 - loss: 1.5525 - val_accuracy: 0.3330 - val_loss: 3.0065\nEpoch 45/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5584 - loss: 1.5339 - val_accuracy: 0.3470 - val_loss: 2.9013\nEpoch 46/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5671 - loss: 1.5035 - val_accuracy: 0.3438 - val_loss: 2.9364\nEpoch 47/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5733 - loss: 1.4821 - val_accuracy: 0.3374 - val_loss: 3.0392\nEpoch 48/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5761 - loss: 1.4649 - val_accuracy: 0.3592 - val_loss: 2.8880\nEpoch 49/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5801 - loss: 1.4423 - val_accuracy: 0.3452 - val_loss: 2.9514\nEpoch 50/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5864 - loss: 1.4217 - val_accuracy: 0.3528 - val_loss: 2.9542\nRestoring model weights from the end of the best epoch: 48.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model\nmodel.save(\"allnighter_3592.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:13:23.885106Z","iopub.execute_input":"2024-10-29T21:13:23.886049Z","iopub.status.idle":"2024-10-29T21:13:24.230194Z","shell.execute_reply.started":"2024-10-29T21:13:23.885994Z","shell.execute_reply":"2024-10-29T21:13:24.229160Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(x_test).argmax(axis=1)\ndf = pd.DataFrame(predictions, columns=[\"Label\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:13:26.200976Z","iopub.execute_input":"2024-10-29T21:13:26.201772Z","iopub.status.idle":"2024-10-29T21:13:26.845333Z","shell.execute_reply.started":"2024-10-29T21:13:26.201730Z","shell.execute_reply":"2024-10-29T21:13:26.844236Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:13:28.984705Z","iopub.execute_input":"2024-10-29T21:13:28.985472Z","iopub.status.idle":"2024-10-29T21:13:28.994861Z","shell.execute_reply.started":"2024-10-29T21:13:28.985431Z","shell.execute_reply":"2024-10-29T21:13:28.993944Z"},"trusted":true},"execution_count":200,"outputs":[{"execution_count":200,"output_type":"execute_result","data":{"text/plain":"      Label\n0        69\n1        88\n2         6\n3        55\n4        71\n...     ...\n9995     92\n9996     21\n9997     51\n9998     42\n9999     92\n\n[10000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>92</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.index.name = \"Id\"","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:13:33.116544Z","iopub.execute_input":"2024-10-29T21:13:33.117299Z","iopub.status.idle":"2024-10-29T21:13:33.121413Z","shell.execute_reply.started":"2024-10-29T21:13:33.117250Z","shell.execute_reply":"2024-10-29T21:13:33.120382Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"submission_35vac.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:13:35.678173Z","iopub.execute_input":"2024-10-29T21:13:35.679055Z","iopub.status.idle":"2024-10-29T21:13:35.695229Z","shell.execute_reply.started":"2024-10-29T21:13:35.679014Z","shell.execute_reply":"2024-10-29T21:13:35.694491Z"},"trusted":true},"execution_count":203,"outputs":[]}]}