{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84511,"databundleVersionId":9468663,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T21:52:47.142078Z","iopub.execute_input":"2024-10-29T21:52:47.142432Z","iopub.status.idle":"2024-10-29T21:52:47.149961Z","shell.execute_reply.started":"2024-10-29T21:52:47.142399Z","shell.execute_reply":"2024-10-29T21:52:47.148974Z"},"trusted":true},"execution_count":232,"outputs":[{"name":"stdout","text":"/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_fine.npy\n/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_coarse.npy\n/kaggle/input/dl-itba-cifar-100-2024-q-1/fine_label_names.pck\n/kaggle/input/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck\n/kaggle/input/dl-itba-cifar-100-2024-q-1/x_test.npy\n/kaggle/input/dl-itba-cifar-100-2024-q-1/x_train.npy\n","output_type":"stream"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.157321Z","iopub.execute_input":"2024-10-29T21:52:47.157614Z","iopub.status.idle":"2024-10-29T21:52:47.164401Z","shell.execute_reply.started":"2024-10-29T21:52:47.157582Z","shell.execute_reply":"2024-10-29T21:52:47.163421Z"},"trusted":true},"execution_count":233,"outputs":[{"name":"stdout","text":"The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten, ReLU, PReLU, Activation\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop\nfrom tensorflow.keras.regularizers import l1, l2\nfrom tensorflow.keras.constraints import MaxNorm\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers, models, regularizers, constraints","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.179293Z","iopub.execute_input":"2024-10-29T21:52:47.179583Z","iopub.status.idle":"2024-10-29T21:52:47.185866Z","shell.execute_reply.started":"2024-10-29T21:52:47.179552Z","shell.execute_reply":"2024-10-29T21:52:47.184968Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"x_train = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/x_train.npy\")\nx_test = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/x_test.npy\")\ny_train_coarse = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_coarse.npy\")\ny_train_fine = np.load(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/y_train_fine.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.187261Z","iopub.execute_input":"2024-10-29T21:52:47.187595Z","iopub.status.idle":"2024-10-29T21:52:47.260055Z","shell.execute_reply.started":"2024-10-29T21:52:47.187562Z","shell.execute_reply":"2024-10-29T21:52:47.259231Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.261637Z","iopub.execute_input":"2024-10-29T21:52:47.261973Z","iopub.status.idle":"2024-10-29T21:52:47.265781Z","shell.execute_reply.started":"2024-10-29T21:52:47.261909Z","shell.execute_reply":"2024-10-29T21:52:47.264819Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/fine_label_names.pck\", \"rb\") as f:\n    labels_fine = pickle.load(f)\nwith open(\"/kaggle/input/dl-itba-cifar-100-2024-q-1/coarse_label_names.pck\", \"rb\") as f:\n    labels_coarse = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.266932Z","iopub.execute_input":"2024-10-29T21:52:47.267246Z","iopub.status.idle":"2024-10-29T21:52:47.279022Z","shell.execute_reply.started":"2024-10-29T21:52:47.267214Z","shell.execute_reply":"2024-10-29T21:52:47.278231Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"y_train_fine.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.280821Z","iopub.execute_input":"2024-10-29T21:52:47.281157Z","iopub.status.idle":"2024-10-29T21:52:47.289909Z","shell.execute_reply.started":"2024-10-29T21:52:47.281115Z","shell.execute_reply":"2024-10-29T21:52:47.289132Z"},"trusted":true},"execution_count":238,"outputs":[{"execution_count":238,"output_type":"execute_result","data":{"text/plain":"(50000,)"},"metadata":{}}]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.291027Z","iopub.execute_input":"2024-10-29T21:52:47.291360Z","iopub.status.idle":"2024-10-29T21:52:47.300187Z","shell.execute_reply.started":"2024-10-29T21:52:47.291320Z","shell.execute_reply":"2024-10-29T21:52:47.299324Z"},"trusted":true},"execution_count":239,"outputs":[{"execution_count":239,"output_type":"execute_result","data":{"text/plain":"(50000, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"x_train,x_val, y_train, y_val = train_test_split(x_train, y_train_fine, test_size=0.1, stratify=y_train_fine)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.302070Z","iopub.execute_input":"2024-10-29T21:52:47.302713Z","iopub.status.idle":"2024-10-29T21:52:47.381275Z","shell.execute_reply.started":"2024-10-29T21:52:47.302669Z","shell.execute_reply":"2024-10-29T21:52:47.380292Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"y_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.382833Z","iopub.execute_input":"2024-10-29T21:52:47.383165Z","iopub.status.idle":"2024-10-29T21:52:47.389127Z","shell.execute_reply.started":"2024-10-29T21:52:47.383131Z","shell.execute_reply":"2024-10-29T21:52:47.388330Z"},"trusted":true},"execution_count":241,"outputs":[{"execution_count":241,"output_type":"execute_result","data":{"text/plain":"(5000,)"},"metadata":{}}]},{"cell_type":"code","source":"x_val.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.390115Z","iopub.execute_input":"2024-10-29T21:52:47.390395Z","iopub.status.idle":"2024-10-29T21:52:47.401682Z","shell.execute_reply.started":"2024-10-29T21:52:47.390363Z","shell.execute_reply":"2024-10-29T21:52:47.400844Z"},"trusted":true},"execution_count":242,"outputs":[{"execution_count":242,"output_type":"execute_result","data":{"text/plain":"(5000, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"x_train_horizontal_flip= x_train[:,:,::-1,:]\n#x_train_vertical_flip = x_train[:,::-1,:,:]\n#x_train_vh_flip =x_train[:, ::-1, ::-1, :]\n\n#x_train_dup = np.concatenate([x_train,x_train_horizontal_flip,x_train_vertical_flip,x_train_vh_flip],axis=0)\nx_train_dup = np.concatenate([x_train,x_train_horizontal_flip],axis=0)\n#y_train_dup = np.concatenate([y_train, y_train,y_train, y_train], axis=0)\ny_train_dup = np.concatenate([y_train, y_train], axis=0)\n\nx_train_bis = x_train_dup.copy()\nx_train_bis_bis = x_train_dup.copy()\n\n#desplazamientos right and left \nx_train_bis[:,:,1:,:] =x_train_dup[:,:,:-1,:]\nx_train_bis_bis[:,:,:-1,:] =x_train_dup[:,:,1:,:]\n\nx_train_dup = np.concatenate([x_train_dup, x_train_bis, x_train_bis_bis],axis=0)\ny_train_dup = np.concatenate([y_train_dup, y_train_dup, y_train_dup], axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:47.403471Z","iopub.execute_input":"2024-10-29T21:52:47.403752Z","iopub.status.idle":"2024-10-29T21:52:48.686067Z","shell.execute_reply.started":"2024-10-29T21:52:47.403721Z","shell.execute_reply":"2024-10-29T21:52:48.684982Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"code","source":"print(f'Original dataset size: {len(x_train)}')\nprint(f'Augmented dataset size: {len(x_train_dup)}')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:48.687384Z","iopub.execute_input":"2024-10-29T21:52:48.687711Z","iopub.status.idle":"2024-10-29T21:52:48.695337Z","shell.execute_reply.started":"2024-10-29T21:52:48.687676Z","shell.execute_reply":"2024-10-29T21:52:48.694216Z"},"trusted":true},"execution_count":244,"outputs":[{"name":"stdout","text":"Original dataset size: 45000\nAugmented dataset size: 270000\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train_dup.shape, y_train_dup.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:48.696845Z","iopub.execute_input":"2024-10-29T21:52:48.697147Z","iopub.status.idle":"2024-10-29T21:52:48.704126Z","shell.execute_reply.started":"2024-10-29T21:52:48.697115Z","shell.execute_reply":"2024-10-29T21:52:48.703313Z"},"trusted":true},"execution_count":245,"outputs":[{"execution_count":245,"output_type":"execute_result","data":{"text/plain":"((270000, 32, 32, 3), (270000,))"},"metadata":{}}]},{"cell_type":"code","source":"from datetime import datetime\nimport keras","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:52:48.705176Z","iopub.execute_input":"2024-10-29T21:52:48.705462Z","iopub.status.idle":"2024-10-29T21:52:48.712612Z","shell.execute_reply.started":"2024-10-29T21:52:48.705430Z","shell.execute_reply":"2024-10-29T21:52:48.711772Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"def create_model(input_shape=(32, 32, 3),l2_lambda=0.001):\n    # Input layer for images\n    inputs = layers.Input(shape=input_shape)\n    \n    # Flattening layer\n    x = layers.Flatten()(inputs)\n    \n    # Normalization layer\n    x = layers.Lambda(lambda x: x/np.float16(255.0))(x)\n    \n    # Dense layers with L2 regularization, dropout, and batch normalization\n    n = 10\n    for i in range(6):\n        x = Dense(2**n)(x)#,\n                  #kernel_regularizer=regularizers.L2(l2_lambda))(x)\n        x = BatchNormalization()(x)\n        x = PReLU()(x)\n        x = Dropout(0.3)(x)\n    \n    # Output layer with softmax for 100 classes\n    fine_output = layers.Dense(100, activation='softmax', name='fine_output')(x)   \n  \n    # Create model\n    model = models.Model(inputs=inputs, outputs=[fine_output], name=f\"mlp_allnighter\")\n    \n    return model\n\nprint(f\"Success at {datetime.now().time()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:57:57.128674Z","iopub.execute_input":"2024-10-29T21:57:57.129177Z","iopub.status.idle":"2024-10-29T21:57:57.137670Z","shell.execute_reply.started":"2024-10-29T21:57:57.129137Z","shell.execute_reply":"2024-10-29T21:57:57.136651Z"},"trusted":true},"execution_count":258,"outputs":[{"name":"stdout","text":"Success at 21:57:57.133776\n","output_type":"stream"}]},{"cell_type":"code","source":"model = create_model()\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-4),\n    loss={'fine_output': 'sparse_categorical_crossentropy'},\n    metrics={'fine_output': 'accuracy' }\n             )\n\n# Display the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:58:01.639820Z","iopub.execute_input":"2024-10-29T21:58:01.640227Z","iopub.status.idle":"2024-10-29T21:58:01.811748Z","shell.execute_reply.started":"2024-10-29T21:58:01.640190Z","shell.execute_reply":"2024-10-29T21:58:01.810886Z"},"trusted":true},"execution_count":259,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"mlp_allnighter\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_allnighter\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_36 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_36 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lambda_36 (\u001b[38;5;33mLambda\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_140 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m3,146,752\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_140         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_21 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_80 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_141 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_141         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_22 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_81 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_142 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_142         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_23 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_82 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_143 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_143         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_24 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_83 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_144 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_144         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_25 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_84 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_145 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_145         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_26 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_85 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m102,500\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lambda_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,146,752</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_140         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_141         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_142         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_143         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_144         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_145         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ p_re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,500</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,527,972\u001b[0m (32.53 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,527,972</span> (32.53 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,515,684\u001b[0m (32.48 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,515,684</span> (32.48 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m12,288\u001b[0m (48.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> (48.00 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Early stopping callback\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True,verbose= 1)\ntb = TensorBoard(log_dir=\"logs\")\nrlrop = ReduceLROnPlateau(\n    monitor=\"val_accuracy\",  # Monitor fine output validation accuracy\n    factor=0.5,\n    patience=3,\n    verbose=1,\n    min_lr=1e-5)\ncallbacks = [early_stopping, tb, rlrop]","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:58:06.935950Z","iopub.execute_input":"2024-10-29T21:58:06.936347Z","iopub.status.idle":"2024-10-29T21:58:06.942579Z","shell.execute_reply.started":"2024-10-29T21:58:06.936307Z","shell.execute_reply":"2024-10-29T21:58:06.941547Z"},"trusted":true},"execution_count":260,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nhistory = model.fit(x=x_train_dup,   \n                    y={'fine_output': y_train_dup},\n                    validation_data=(x_val, {'fine_output': y_val}),\n                    epochs=50,                        \n                    batch_size=512,  # approximately 1000 batches per epoch                    \n                    callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T21:58:13.392873Z","iopub.execute_input":"2024-10-29T21:58:13.393878Z","iopub.status.idle":"2024-10-29T22:02:16.938580Z","shell.execute_reply.started":"2024-10-29T21:58:13.393833Z","shell.execute_reply":"2024-10-29T22:02:16.937754Z"},"trusted":true},"execution_count":261,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 26ms/step - accuracy: 0.0388 - loss: 4.6207 - val_accuracy: 0.1346 - val_loss: 3.7131 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1176 - loss: 3.7820 - val_accuracy: 0.1690 - val_loss: 3.4884 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1600 - loss: 3.5206 - val_accuracy: 0.2032 - val_loss: 3.3061 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1891 - loss: 3.3470 - val_accuracy: 0.1932 - val_loss: 3.3460 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2150 - loss: 3.2071 - val_accuracy: 0.2354 - val_loss: 3.1463 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2346 - loss: 3.1000 - val_accuracy: 0.2434 - val_loss: 3.1168 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2505 - loss: 3.0096 - val_accuracy: 0.2504 - val_loss: 3.0652 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2678 - loss: 2.9187 - val_accuracy: 0.2502 - val_loss: 3.0760 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2822 - loss: 2.8454 - val_accuracy: 0.2760 - val_loss: 2.9550 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2975 - loss: 2.7679 - val_accuracy: 0.2896 - val_loss: 2.8844 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3077 - loss: 2.7032 - val_accuracy: 0.2958 - val_loss: 2.8591 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3221 - loss: 2.6404 - val_accuracy: 0.2742 - val_loss: 2.9498 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3326 - loss: 2.5936 - val_accuracy: 0.3026 - val_loss: 2.8940 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3446 - loss: 2.5275 - val_accuracy: 0.2920 - val_loss: 2.9024 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3552 - loss: 2.4767 - val_accuracy: 0.2992 - val_loss: 2.9016 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3630 - loss: 2.4296 - val_accuracy: 0.3060 - val_loss: 2.8216 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3754 - loss: 2.3772 - val_accuracy: 0.3236 - val_loss: 2.7691 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3845 - loss: 2.3317 - val_accuracy: 0.3094 - val_loss: 2.8643 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3931 - loss: 2.2929 - val_accuracy: 0.3326 - val_loss: 2.7314 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4030 - loss: 2.2469 - val_accuracy: 0.3266 - val_loss: 2.7655 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4102 - loss: 2.2130 - val_accuracy: 0.3338 - val_loss: 2.7502 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4176 - loss: 2.1672 - val_accuracy: 0.3316 - val_loss: 2.7752 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4263 - loss: 2.1313 - val_accuracy: 0.3302 - val_loss: 2.7458 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4338 - loss: 2.0957 - val_accuracy: 0.3344 - val_loss: 2.7470 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4433 - loss: 2.0539 - val_accuracy: 0.3136 - val_loss: 2.9456 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4505 - loss: 2.0214 - val_accuracy: 0.3296 - val_loss: 2.8143 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m522/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4553 - loss: 1.9899\nEpoch 27: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4553 - loss: 1.9899 - val_accuracy: 0.3284 - val_loss: 2.8198 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4712 - loss: 1.9259 - val_accuracy: 0.3644 - val_loss: 2.6472 - learning_rate: 5.0000e-05\nEpoch 29/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4787 - loss: 1.8943 - val_accuracy: 0.3680 - val_loss: 2.6618 - learning_rate: 5.0000e-05\nEpoch 30/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4829 - loss: 1.8687 - val_accuracy: 0.3650 - val_loss: 2.6913 - learning_rate: 5.0000e-05\nEpoch 31/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4869 - loss: 1.8481 - val_accuracy: 0.3698 - val_loss: 2.6352 - learning_rate: 5.0000e-05\nEpoch 32/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4900 - loss: 1.8351 - val_accuracy: 0.3752 - val_loss: 2.6461 - learning_rate: 5.0000e-05\nEpoch 33/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4962 - loss: 1.8109 - val_accuracy: 0.3734 - val_loss: 2.6775 - learning_rate: 5.0000e-05\nEpoch 34/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5015 - loss: 1.7904 - val_accuracy: 0.3694 - val_loss: 2.6764 - learning_rate: 5.0000e-05\nEpoch 35/50\n\u001b[1m525/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5050 - loss: 1.7741\nEpoch 35: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5050 - loss: 1.7741 - val_accuracy: 0.3696 - val_loss: 2.7031 - learning_rate: 5.0000e-05\nEpoch 36/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5120 - loss: 1.7485 - val_accuracy: 0.3834 - val_loss: 2.6045 - learning_rate: 2.5000e-05\nEpoch 37/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5147 - loss: 1.7272 - val_accuracy: 0.3876 - val_loss: 2.6123 - learning_rate: 2.5000e-05\nEpoch 38/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5177 - loss: 1.7158 - val_accuracy: 0.3804 - val_loss: 2.6310 - learning_rate: 2.5000e-05\nEpoch 39/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5206 - loss: 1.7071 - val_accuracy: 0.3848 - val_loss: 2.6231 - learning_rate: 2.5000e-05\nEpoch 40/50\n\u001b[1m527/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5236 - loss: 1.6856\nEpoch 40: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5236 - loss: 1.6856 - val_accuracy: 0.3868 - val_loss: 2.6361 - learning_rate: 2.5000e-05\nEpoch 41/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5260 - loss: 1.6814 - val_accuracy: 0.3878 - val_loss: 2.6173 - learning_rate: 1.2500e-05\nEpoch 42/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5272 - loss: 1.6716 - val_accuracy: 0.3886 - val_loss: 2.6245 - learning_rate: 1.2500e-05\nEpoch 43/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5276 - loss: 1.6688 - val_accuracy: 0.3912 - val_loss: 2.6174 - learning_rate: 1.2500e-05\nEpoch 44/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5312 - loss: 1.6598 - val_accuracy: 0.3848 - val_loss: 2.6361 - learning_rate: 1.2500e-05\nEpoch 45/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5306 - loss: 1.6548 - val_accuracy: 0.3856 - val_loss: 2.6316 - learning_rate: 1.2500e-05\nEpoch 46/50\n\u001b[1m523/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5314 - loss: 1.6536\nEpoch 46: ReduceLROnPlateau reducing learning rate to 1e-05.\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5314 - loss: 1.6536 - val_accuracy: 0.3852 - val_loss: 2.6423 - learning_rate: 1.2500e-05\nEpoch 47/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5346 - loss: 1.6438 - val_accuracy: 0.3910 - val_loss: 2.6310 - learning_rate: 1.0000e-05\nEpoch 48/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5349 - loss: 1.6398 - val_accuracy: 0.3918 - val_loss: 2.6311 - learning_rate: 1.0000e-05\nEpoch 49/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5370 - loss: 1.6315 - val_accuracy: 0.3880 - val_loss: 2.6305 - learning_rate: 1.0000e-05\nEpoch 50/50\n\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5373 - loss: 1.6320 - val_accuracy: 0.3904 - val_loss: 2.6358 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 48.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Keep on learning with more patience, smaller batch size","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_accuracy', patience=16, restore_best_weights=True,verbose= 1)\ncallbacks = [rlrop, early_stopping, tb]\n\nhistory = model.fit(x=x_train_dup,   \n                    y={'fine_output': y_train_dup},\n                    validation_data=(x_val, {'fine_output': y_val}),\n                    epochs=50,                        \n                    batch_size=128,               \n                    callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:18:42.250511Z","iopub.execute_input":"2024-10-29T22:18:42.250895Z","iopub.status.idle":"2024-10-29T22:27:34.021640Z","shell.execute_reply.started":"2024-10-29T22:18:42.250858Z","shell.execute_reply":"2024-10-29T22:27:34.020181Z"},"trusted":true},"execution_count":274,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9ms/step - accuracy: 0.5393 - loss: 1.6265 - val_accuracy: 0.3880 - val_loss: 2.6774 - learning_rate: 1.0000e-05\nEpoch 2/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5388 - loss: 1.6216 - val_accuracy: 0.3894 - val_loss: 2.6793 - learning_rate: 1.0000e-05\nEpoch 3/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5391 - loss: 1.6174 - val_accuracy: 0.3922 - val_loss: 2.6757 - learning_rate: 1.0000e-05\nEpoch 4/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5414 - loss: 1.6128 - val_accuracy: 0.3896 - val_loss: 2.6774 - learning_rate: 1.0000e-05\nEpoch 5/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5407 - loss: 1.6110 - val_accuracy: 0.3914 - val_loss: 2.6738 - learning_rate: 1.0000e-05\nEpoch 6/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5413 - loss: 1.6063 - val_accuracy: 0.3912 - val_loss: 2.6770 - learning_rate: 1.0000e-05\nEpoch 7/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5463 - loss: 1.5937 - val_accuracy: 0.3906 - val_loss: 2.6891 - learning_rate: 1.0000e-05\nEpoch 8/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5478 - loss: 1.5843 - val_accuracy: 0.3908 - val_loss: 2.6795 - learning_rate: 1.0000e-05\nEpoch 9/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5497 - loss: 1.5822 - val_accuracy: 0.3920 - val_loss: 2.6824 - learning_rate: 1.0000e-05\nEpoch 10/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5502 - loss: 1.5780 - val_accuracy: 0.3948 - val_loss: 2.6766 - learning_rate: 1.0000e-05\nEpoch 11/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5500 - loss: 1.5706 - val_accuracy: 0.3952 - val_loss: 2.6692 - learning_rate: 1.0000e-05\nEpoch 12/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5511 - loss: 1.5683 - val_accuracy: 0.3948 - val_loss: 2.6828 - learning_rate: 1.0000e-05\nEpoch 13/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5523 - loss: 1.5682 - val_accuracy: 0.3922 - val_loss: 2.6773 - learning_rate: 1.0000e-05\nEpoch 14/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5527 - loss: 1.5590 - val_accuracy: 0.3936 - val_loss: 2.6865 - learning_rate: 1.0000e-05\nEpoch 15/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5565 - loss: 1.5503 - val_accuracy: 0.3924 - val_loss: 2.6799 - learning_rate: 1.0000e-05\nEpoch 16/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5543 - loss: 1.5478 - val_accuracy: 0.3958 - val_loss: 2.6842 - learning_rate: 1.0000e-05\nEpoch 17/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5568 - loss: 1.5451 - val_accuracy: 0.3914 - val_loss: 2.6965 - learning_rate: 1.0000e-05\nEpoch 18/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5573 - loss: 1.5414 - val_accuracy: 0.3900 - val_loss: 2.6947 - learning_rate: 1.0000e-05\nEpoch 19/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5586 - loss: 1.5362 - val_accuracy: 0.3926 - val_loss: 2.6830 - learning_rate: 1.0000e-05\nEpoch 20/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5613 - loss: 1.5319 - val_accuracy: 0.3908 - val_loss: 2.6969 - learning_rate: 1.0000e-05\nEpoch 21/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5613 - loss: 1.5208 - val_accuracy: 0.3936 - val_loss: 2.7007 - learning_rate: 1.0000e-05\nEpoch 22/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5648 - loss: 1.5115 - val_accuracy: 0.3932 - val_loss: 2.7015 - learning_rate: 1.0000e-05\nEpoch 23/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5634 - loss: 1.5147 - val_accuracy: 0.3912 - val_loss: 2.6995 - learning_rate: 1.0000e-05\nEpoch 24/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5658 - loss: 1.5114 - val_accuracy: 0.3928 - val_loss: 2.7121 - learning_rate: 1.0000e-05\nEpoch 25/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5651 - loss: 1.5082 - val_accuracy: 0.3968 - val_loss: 2.7053 - learning_rate: 1.0000e-05\nEpoch 26/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5707 - loss: 1.4924 - val_accuracy: 0.3938 - val_loss: 2.7169 - learning_rate: 1.0000e-05\nEpoch 27/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5685 - loss: 1.4967 - val_accuracy: 0.3942 - val_loss: 2.7112 - learning_rate: 1.0000e-05\nEpoch 28/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5703 - loss: 1.4883 - val_accuracy: 0.3930 - val_loss: 2.7140 - learning_rate: 1.0000e-05\nEpoch 29/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5701 - loss: 1.4868 - val_accuracy: 0.3926 - val_loss: 2.7149 - learning_rate: 1.0000e-05\nEpoch 30/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5729 - loss: 1.4793 - val_accuracy: 0.3936 - val_loss: 2.7187 - learning_rate: 1.0000e-05\nEpoch 31/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5761 - loss: 1.4678 - val_accuracy: 0.3968 - val_loss: 2.7228 - learning_rate: 1.0000e-05\nEpoch 32/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5743 - loss: 1.4729 - val_accuracy: 0.3948 - val_loss: 2.7300 - learning_rate: 1.0000e-05\nEpoch 33/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5758 - loss: 1.4695 - val_accuracy: 0.3966 - val_loss: 2.7254 - learning_rate: 1.0000e-05\nEpoch 34/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5803 - loss: 1.4508 - val_accuracy: 0.3978 - val_loss: 2.7156 - learning_rate: 1.0000e-05\nEpoch 35/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5781 - loss: 1.4584 - val_accuracy: 0.3984 - val_loss: 2.7301 - learning_rate: 1.0000e-05\nEpoch 36/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5812 - loss: 1.4471 - val_accuracy: 0.3952 - val_loss: 2.7197 - learning_rate: 1.0000e-05\nEpoch 37/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5805 - loss: 1.4458 - val_accuracy: 0.3936 - val_loss: 2.7371 - learning_rate: 1.0000e-05\nEpoch 38/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5822 - loss: 1.4434 - val_accuracy: 0.3978 - val_loss: 2.7301 - learning_rate: 1.0000e-05\nEpoch 39/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5843 - loss: 1.4339 - val_accuracy: 0.3952 - val_loss: 2.7405 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5853 - loss: 1.4303 - val_accuracy: 0.3970 - val_loss: 2.7273 - learning_rate: 1.0000e-05\nEpoch 41/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5852 - loss: 1.4281 - val_accuracy: 0.3934 - val_loss: 2.7458 - learning_rate: 1.0000e-05\nEpoch 42/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5877 - loss: 1.4213 - val_accuracy: 0.3950 - val_loss: 2.7561 - learning_rate: 1.0000e-05\nEpoch 43/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5894 - loss: 1.4164 - val_accuracy: 0.3980 - val_loss: 2.7323 - learning_rate: 1.0000e-05\nEpoch 44/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5897 - loss: 1.4133 - val_accuracy: 0.3972 - val_loss: 2.7414 - learning_rate: 1.0000e-05\nEpoch 45/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5903 - loss: 1.4055 - val_accuracy: 0.3970 - val_loss: 2.7466 - learning_rate: 1.0000e-05\nEpoch 46/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5909 - loss: 1.4018 - val_accuracy: 0.3924 - val_loss: 2.7472 - learning_rate: 1.0000e-05\nEpoch 47/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5940 - loss: 1.3967 - val_accuracy: 0.4020 - val_loss: 2.7565 - learning_rate: 1.0000e-05\nEpoch 48/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5947 - loss: 1.3901 - val_accuracy: 0.3948 - val_loss: 2.7595 - learning_rate: 1.0000e-05\nEpoch 49/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5933 - loss: 1.3924 - val_accuracy: 0.3982 - val_loss: 2.7545 - learning_rate: 1.0000e-05\nEpoch 50/50\n\u001b[1m2110/2110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.5975 - loss: 1.3835 - val_accuracy: 0.3970 - val_loss: 2.7475 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 47.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model after 50 epochs\nmodel.save(\"allnighter_40.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:28:21.837132Z","iopub.execute_input":"2024-10-29T22:28:21.837535Z","iopub.status.idle":"2024-10-29T22:28:22.215731Z","shell.execute_reply.started":"2024-10-29T22:28:21.837497Z","shell.execute_reply":"2024-10-29T22:28:22.214693Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"markdown","source":"Just a few more epochs...","metadata":{}},{"cell_type":"code","source":"history = model.fit(x=x_train_dup,   \n                    y={'fine_output': y_train_dup},\n                    validation_data=(x_val, {'fine_output': y_val}),\n                    epochs=100,                        \n                    batch_size=64,               \n                    callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:32:46.168734Z","iopub.execute_input":"2024-10-29T22:32:46.169702Z","iopub.status.idle":"2024-10-29T22:37:55.424436Z","shell.execute_reply.started":"2024-10-29T22:32:46.169647Z","shell.execute_reply":"2024-10-29T22:37:55.423610Z"},"trusted":true},"execution_count":282,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.5620 - loss: 1.5177 - val_accuracy: 0.3940 - val_loss: 2.7558 - learning_rate: 1.0000e-05\nEpoch 2/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5672 - loss: 1.5048 - val_accuracy: 0.3924 - val_loss: 2.7782 - learning_rate: 1.0000e-05\nEpoch 3/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5648 - loss: 1.5087 - val_accuracy: 0.3938 - val_loss: 2.7460 - learning_rate: 1.0000e-05\nEpoch 4/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5683 - loss: 1.5016 - val_accuracy: 0.3974 - val_loss: 2.7536 - learning_rate: 1.0000e-05\nEpoch 5/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5700 - loss: 1.4921 - val_accuracy: 0.3946 - val_loss: 2.7414 - learning_rate: 1.0000e-05\nEpoch 6/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5714 - loss: 1.4861 - val_accuracy: 0.3962 - val_loss: 2.7372 - learning_rate: 1.0000e-05\nEpoch 7/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5724 - loss: 1.4822 - val_accuracy: 0.3966 - val_loss: 2.7512 - learning_rate: 1.0000e-05\nEpoch 8/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5744 - loss: 1.4707 - val_accuracy: 0.4014 - val_loss: 2.7423 - learning_rate: 1.0000e-05\nEpoch 9/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5730 - loss: 1.4767 - val_accuracy: 0.3986 - val_loss: 2.7401 - learning_rate: 1.0000e-05\nEpoch 10/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5756 - loss: 1.4652 - val_accuracy: 0.3976 - val_loss: 2.7461 - learning_rate: 1.0000e-05\nEpoch 11/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.5760 - loss: 1.4649 - val_accuracy: 0.3924 - val_loss: 2.7476 - learning_rate: 1.0000e-05\nEpoch 12/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5784 - loss: 1.4571 - val_accuracy: 0.3988 - val_loss: 2.7560 - learning_rate: 1.0000e-05\nEpoch 13/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5806 - loss: 1.4493 - val_accuracy: 0.3968 - val_loss: 2.7482 - learning_rate: 1.0000e-05\nEpoch 14/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5808 - loss: 1.4491 - val_accuracy: 0.3994 - val_loss: 2.7415 - learning_rate: 1.0000e-05\nEpoch 15/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.5829 - loss: 1.4401 - val_accuracy: 0.3964 - val_loss: 2.7573 - learning_rate: 1.0000e-05\nEpoch 16/100\n\u001b[1m4219/4219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.5830 - loss: 1.4388 - val_accuracy: 0.3958 - val_loss: 2.7711 - learning_rate: 1.0000e-05\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Save predictions","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(x_test).argmax(axis=1)\ndf = pd.DataFrame(predictions, columns=[\"Label\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:28:25.958995Z","iopub.execute_input":"2024-10-29T22:28:25.959844Z","iopub.status.idle":"2024-10-29T22:28:26.632384Z","shell.execute_reply.started":"2024-10-29T22:28:25.959801Z","shell.execute_reply":"2024-10-29T22:28:26.631617Z"},"trusted":true},"execution_count":276,"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:28:29.600290Z","iopub.execute_input":"2024-10-29T22:28:29.600677Z","iopub.status.idle":"2024-10-29T22:28:29.610789Z","shell.execute_reply.started":"2024-10-29T22:28:29.600638Z","shell.execute_reply":"2024-10-29T22:28:29.609815Z"},"trusted":true},"execution_count":277,"outputs":[{"execution_count":277,"output_type":"execute_result","data":{"text/plain":"      Label\n0        49\n1        42\n2        27\n3        15\n4        71\n...     ...\n9995     83\n9996     21\n9997     51\n9998     42\n9999      0\n\n[10000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.index.name = \"Id\"","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:28:33.696276Z","iopub.execute_input":"2024-10-29T22:28:33.696653Z","iopub.status.idle":"2024-10-29T22:28:33.701092Z","shell.execute_reply.started":"2024-10-29T22:28:33.696616Z","shell.execute_reply":"2024-10-29T22:28:33.700078Z"},"trusted":true},"execution_count":279,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"submission_40vac.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T22:31:10.244539Z","iopub.execute_input":"2024-10-29T22:31:10.245415Z","iopub.status.idle":"2024-10-29T22:31:10.261848Z","shell.execute_reply.started":"2024-10-29T22:31:10.245372Z","shell.execute_reply":"2024-10-29T22:31:10.260965Z"},"trusted":true},"execution_count":281,"outputs":[]}]}